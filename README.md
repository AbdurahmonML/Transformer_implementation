# Transformer Model from Scratch

## Overview
In this project, I built a Transformer model from scratch, including the implementation of attention mechanisms. The primary goal was to create a model capable of translating English to French.

## Features
- **Transformer Architecture**: Implemented the entire Transformer model, including attention layers.
- **Language Translation**: Trained the model specifically for translating text from English to French.

## Training the Model
To train the model, follow these steps:

1. **Run the Notebook**: Open and execute `train.ipynb`. The notebook contains all the necessary code to train the model.
2. **No External Imports**: I ensured that all required files are included within the project to minimize the risk of errors during execution.

### Notes
- The performance of the model may not be optimal due to the limited size of the dataset used for training. However, it is capable of producing reasonable translations despite the constraints.

## Acknowledgments
This project is inspired by the original Transformer paper and various resources on neural network implementations.
